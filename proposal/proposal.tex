\documentclass[12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the preamble of the .tex file and is the place where you should specify which packages to include and what settings you want for particular commands.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\usepackage{adjustbox, amsmath, amssymb, amsthm, blindtext, bm, bbm, dblfloatfix, esint, fancyhdr, float, graphicx, letltxmacro, marginnote, mathtools, subcaption, xcolor, titlesec, esint, mdframed}
\usepackage[margin=1.0in]{geometry}
\usepackage{chngcntr}
\usepackage[space]{grffile}
\usepackage[labelfont=bf]{caption}
\usepackage[shortlabels]{enumitem}
\usepackage{setspace}

% the listings package can be used to include direct code snippets
\usepackage{listings}
\usepackage{color}

\onehalfspacing

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}

\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}

% the following lines take care of the headers and footers for each page
\makeatletter
        \newcommand{\rightorleftmark}{%
	\begingroup\protected@edef\x{\rightmark}%
	\ifx\x\@empty
    		\endgroup\nouppercase{\leftmark}
	\else
    		\endgroup\rightmark
  	\fi}
\makeatother

\makeatletter
	\begingroup
  		\catcode`\_=\active
  		\protected\gdef_{\@ifnextchar|\subtextup\sb}
 	\endgroup
	\def\subtextup|#1|{\sb{\textup{#1}}}
	\AtBeginDocument{\catcode`\_=12 \mathcode`\_=32768}
\makeatother

\pagestyle{fancyplain}
\fancyhf{}
\cfoot{ \fancyplain{}{\thepage} }
\renewcommand{\footrulewidth}{0.4pt}
\renewcommand{\vec}[1]{\boldsymbol{\mathbf{#1}}}

\allowdisplaybreaks

\begin{document}

	\title{\vspace{-10mm}Federated Machine Learning}
	\author{Oh Joon Kwon}
	\date{November 1, 2019}

	\maketitle
	
	\section{Introduction}
	
	There has been a recent surge of interest in machine learning in both academia and industry. Now, it has become harder to find areas where machine learning has not been applied as the areas of applications are no longer confined by disciplines, from engineering to history. However, the need for better and more scalable machine learning models and algorithms often leads to ethical concerns. 
	
	\vspace{3mm}
	
	\noindent For instance, some implementations without the full understanding of the dataset and model have perpetuated unfairness in socio-economic contexts \cite{nnorient}. Generative algorithms, such as Generative Adversarial Nets and GPT-2, have raised some concerns of dispersing misinformation by malicious parties \cite{leak}. Moreover, fundamental data collection methods for training and validating models have been often overlooked as necessary components of large-scale machine learning, though many practices have been deemed to have violated individual privacy.
	
	\vspace{3mm}
	
	\noindent With these problems in mind, researchers are now focusing on the balanced development of ethics and technologies that could help mitigate these troublesome aspects of machine learning. Recent papers suggest some fundamental solutions in terms of homomorphic encryption protocols, but it is computationally expensive and algebraically limiting at times while providing the most secure methods of privacy preserving machine learning \cite{ppml}.  The most plausible solution to privacy concerns is Federated Machine Learning, a multi-party computation (MPC) framework that could guarantee individual privacy without compromising the accuracy of a generalized model. 
	
	\vspace{3mm}
	
	\noindent This project aims to implement the recent privacy-preserving multi-party computation frameworks such as Federated Averaging and Split Neural Nets without networking components. As it is a relatively new field of machine learning, we also plan to investigate possible attacks on Federated Machine Learning schema using information leakage. Time permitting, we plan to implement these information leakage attacks in our demo.
	
	\section{Background}
	Federated Machine Learning proposes a solution to privacy-preserving large-scale machine learning by training models locally on an individual client device then updating the model parameters or finishing the rest of the model training on the central server.
	
	\vspace{3mm}
	
	\subsection*{Problem Statement.}
	
    \noindent We would like to first define the fundamental objective in machine learning called the ``finite-sum problem:
	$$ \min_{\vec{\theta} \in \mathbb{R}^d} \frac{1}{n} \sum_{i=1}^n f_i(\vec{\theta})\text{"} $$
	
	\noindent In the context of machine learning, we would like to minimize our loss of predictions over examples, so we can take $f$ to be a loss function, $f_i(\vec{\theta}) = l(x_i, y_i; \vec{\theta})$ where $l$ is a loss on the prediction made on example $(x_i, y_i)$ with a set of model parameters $\vec{\theta}$. For the multi-party computation scheme with data partitioned over $K$-clients. Let $S_k$ be the set of indices of data points on client $k \in \{1, 2, \dots K \}$ with $n_k := |S_k|$. We can restate the problem to ``the Federated Machine Learning context:
	
	$$ \min_{\vec{\theta} \in \mathbb{R}^d} f(\vec{\theta}) = \sum_{k=1}^K \frac{n_k}{n} F_k(\vec{\theta}) \qquad \qquad F_k(\vec{\theta}) := \frac{1}{n_k} \sum_{i \in S_k} f_i(\vec{\theta}) \qquad \qquad n = \sum_{k=1}^K n_k$$
	
	\vspace{3mm}
	
	\noindent Moreover, the optimization problem implicit in federated learning scheme is often based on the following assumptions \cite{fml}. This problem is often termed Federated Optimization.
	\begin{enumerate}
	    \item[(1)] \textbf{Non-IID}. The training data on a client is based on the usage by a user, which is often not representative of the population.
	    \item[(2)] \textbf{Unbalanced}. Some users can be heavy users while others are not.
	    \item[(3)] \textbf{Massively Distributed}. The number of clients participating in an optimization is much larger than the average number of examples per client. That is, $|C_t| \gg \sum_{k=1}^K n_k / K$
	    \item[(4)] \textbf{Limited Communication}. Oftentimes, clients are offline or on limited bandwidth/expensive connections.
	\end{enumerate}
	
	\vspace{3mm}
	
	\subsection*{Algorithms.}
	\noindent There are several proposed algorithms for solving the Federated Optimization problem. One of the most promising algorithms is \textbf{Federated Averaging}, which is already being used in the Google Keyboard app. The algorithm not only provides privacy by design, but also personalizes models to individual users. It also claims to be more resource efficient in terms of communication rounds. Federated Stochastic Gradient Descent (FedSGD) is a special case of Federated Averaging, where the algorithm is given below:\cite{fml}
	
	\begin{mdframed}
		\textbf{Server Executes} : 
		\begin{enumerate}[\qquad]
			\item \text{Initialize the parameters $\vec{\theta}_0$.}
			\item \textbf{for }\text{each round $t=1, 2, \dots $} \textbf{do}
			\item \text{\qquad Pick random sample of clients $C_t$ where $1 \leq |C_t| \leq K$.}
			\item \qquad \textbf{for }\text{each client $k \in C_t$} \textbf{in parallel do}
			\item \qquad \qquad $\vec{\theta}_{t+1}^k \leftarrow \text{ClientUpdate} (k, \vec{\theta}_t)$
			\item \qquad $\vec{\theta}_{t+1} \leftarrow \sum\limits_{k=1}^K \dfrac{n_k}{n} \vec{\theta}_{t+1}^k$
		\end{enumerate}
		\textbf{Each Client Executes ClientUpdate}$(k, \vec{\theta})$:
		\begin{enumerate}[\qquad]
		    \item \text{Batch data $S_k$ into collection $\mathcal{B}$.}
		    \item \textbf{for }\text{each local epoch $i=1, 2, \dots, E$} \textbf{do}
		    \item \qquad \textbf{for }\text{each batch $b \in \mathcal{B}$} \textbf{do}
		    \item \qquad \qquad $\vec{\theta} \leftarrow \vec{\theta} - \alpha \cdot \nabla F_k (\vec{\theta}; b)$
		    \item \text{Return $\vec{\theta}$ to server}
		\end{enumerate}
    \end{mdframed}

    \noindent Another algorithm is \textbf{Split Neural Nets (SplitNN)}, where a part of training (upto a ``cut layer'') is done locally then the rest is done on the central server. For notation, let $\vec{A}_t$ be the client-side network weights with $\varphi$ as random intializing distribution, $\vec{S}_t$ be the server-side network weights, and $\vec{W}_t$ be all network weights, $[\vec{A}_t, \vec{S}_t]$. Here, we will use $l$ for denoting a general loss function to be minimized. The algorithm is claimed to have achieved computation resource and bandwidth efficiency \cite{splitnn}. The vanilla configuration of the algorithm is done in the following way:\cite{nopeek}

	\begin{mdframed}
		\textbf{Server Executes} : 
		\begin{enumerate}[\qquad]
			\item \textbf{for }\text{each round $t=1, 2, \dots $} \textbf{do}
			\item \qquad \textbf{for }\text{each client $k \in C_t$} \textbf{in parallel do}
			\item \qquad \qquad $\vec{A}_t^k \leftarrow \text{ClientUpdate}(k,t)$
			\item \qquad \qquad $\hat{\vec{Y}}_t^k \leftarrow f(f(b, \vec{A}_t^k), \vec{S}_t^k)$
			\item \qquad \qquad $\vec{W}_t \leftarrow \vec{W}_t - \alpha \cdot \nabla F_k(\vec{W}_t; \hat{\vec{Y}}_t^k)$
			\item \qquad \qquad \text{Send $\nabla F_k(\vec{A}_t^k; \hat{\vec{Y}}_t^k)$ to client $k$ for ClientBackprop$(k,t)$}
		\end{enumerate}
		\textbf{Each Client Executes ClientUpdate}$(k, t)$:
		\begin{enumerate}[\qquad]
		    \item $\vec{A}_t^k = \varphi$
		    \item \textbf{for }\text{each batch $b \in \mathcal{B}$} \textbf{do}
		    \item \qquad \text{Concatenate logits $f(b, \vec{A}_t^k)$ to $\vec{A}_t^k$ (Batch $b$ includes labels)}
		    \item \text{Return $(f(b, \vec{A}_t^k), \vec{A}_t^k)$ to server}
		\end{enumerate}
		\textbf{Each Client Executes ClientBackprop}$(k,t)$:
		\begin{enumerate}[\qquad]
		    \item \textbf{for }\text{each batch $b \in \mathcal{B}$} \textbf{do}
		    \item \qquad $\vec{A}_t^k \leftarrow \vec{A}_t^k - \alpha \cdot \nabla F_k(\vec{A}_t^k; \hat{\vec{Y}}_t^k)$
		\end{enumerate}
    \end{mdframed}
	
	\section{Proposed Methodology}
	We plan to replicate the proposed federated learning algorithms as a demo. Since the project is more focused on the theoretical aspects of Federated Machine Learning, we will not be implementing the remote networking component of the algorithms. Instead, we will ``simulate" the networking environment in a local machine by creating multiple functions representing individual clients and computing server-side computation in \texttt{__main__()} function. 
	
	\vspace{3mm}
	
	\noindent We will investigate the computation and communication efficiency by counting the number of communication rounds when each function is called. We will be timing each computation components done in each client and server to measure computation resource efficiency. Time and resource permitting, we would also like to investigate the scalability of each algorithm.
	
	\vspace{3mm}
	
	\noindent For the dataset, we will be using the MNIST handwritten digits dataset. MNIST dataset will provide sufficient number of examples without resource-heavy features. In order to simulate the non-IID assumption, we will sort the dataset according to the labels and split the dataset into subsets in order (possibly of different size), then assign them to virtual clients. We would like to see how biased individual client data could affect the performance of the algorithm.
	
	\vspace{3mm}
	
	\noindent Time permitting, we would also like to study the possible attacks on distributed learning scheme. Recent studies are now looking into possible attacks taking advantage of information leakage that may be inherent in algorithm/implementation design \cite{reducingleak}. We would like to see how malicious parties can corrupt training data with fake(generated) dataset and extract private information in distributed learning scheme where some information is leaked by design.

	% bibliography style is set to SIAM here. you can experiment with other styles
	\bibliographystyle{siam}
	
	% this line includes all references cited in the document. 
	\bibliography{references.bib}
	
\end{document}
